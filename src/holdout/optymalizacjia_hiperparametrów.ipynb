{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_error_matrix(y_test,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "\n",
    "    precision=  tp / (tp+fp)if (tp+fp) > 0 else 0\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    F1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n",
    "\n",
    "    print(f\"Accuracy:     {accuracy:.4f}\")\n",
    "    print(f\"F1:           {F1:.4f}\")\n",
    "    print(f\"Precision:    {precision:.4f}\")\n",
    "    print(f\"Sensitivity:  {sensitivity:.4f}\")\n",
    "    print(f\"Specificity:  {specificity:.4f}\")\n",
    "    print(f\"TP:           {tp}\")\n",
    "    print(f\"FP:           {fp}\")\n",
    "    print(f\"TN:           {tn}\")\n",
    "    print(f\"FN:           {fn}\")\n",
    "    print(\"         Pred 0    Pred 1\")\n",
    "    print(f\"True 0    {tn:4}     {fp:4}\")\n",
    "    print(f\"True 1    {fn:4}     {tp:4}\")\n",
    "\n",
    "def test_model(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred=model.predict(X_val)\n",
    "    \n",
    "    tn, fp, fn, tp =confusion_matrix(y_val, y_pred).ravel()\n",
    "    \n",
    "    F1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n",
    "    return F1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"dataset_train.csv\")\n",
    "test=pd.read_csv(\"dataset_test.csv\")\n",
    "\n",
    "test['arrytmia'] = test['arrytmia'].apply(lambda x: 1 if x > 1 else x)\n",
    "train['arrytmia'] = train['arrytmia'].apply(lambda x: 1 if x > 1 else x)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns)\n",
    "\n",
    "test = pd.DataFrame(scaler.transform(test), columns=test.columns)\n",
    "\n",
    "\n",
    "\n",
    "X_train = train.iloc[: ,1:].values\n",
    "y_train = train['arrytmia'].values\n",
    "\n",
    "X_test = test.iloc[: ,1:].values\n",
    "y_test = test['arrytmia'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_val, _, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 11:13:27,838] A new study created in memory with name: no-name-14fec4d0-29d7-4e56-8bd6-7bb298b987a6\n",
      "[I 2025-07-16 11:13:29,114] Trial 0 finished with value: 0.9245569620253165 and parameters: {'n_neighbors': 195, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean'}. Best is trial 0 with value: 0.9245569620253165.\n",
      "[I 2025-07-16 11:13:30,197] Trial 1 finished with value: 0.9407053750192516 and parameters: {'n_neighbors': 47, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'manhattan'}. Best is trial 1 with value: 0.9407053750192516.\n",
      "[I 2025-07-16 11:13:31,900] Trial 2 finished with value: 0.9286657859973579 and parameters: {'n_neighbors': 140, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'manhattan'}. Best is trial 1 with value: 0.9407053750192516.\n",
      "[I 2025-07-16 11:13:32,890] Trial 3 finished with value: 1.0 and parameters: {'n_neighbors': 197, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:33,821] Trial 4 finished with value: 1.0 and parameters: {'n_neighbors': 177, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:34,783] Trial 5 finished with value: 0.93763816770346 and parameters: {'n_neighbors': 60, 'weights': 'uniform', 'algorithm': 'brute', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:35,776] Trial 6 finished with value: 0.933047122559542 and parameters: {'n_neighbors': 97, 'weights': 'uniform', 'algorithm': 'kd_tree', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:36,790] Trial 7 finished with value: 0.9307385841250383 and parameters: {'n_neighbors': 116, 'weights': 'uniform', 'algorithm': 'auto', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:37,598] Trial 8 finished with value: 1.0 and parameters: {'n_neighbors': 90, 'weights': 'distance', 'algorithm': 'kd_tree', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:41,210] Trial 9 finished with value: 1.0 and parameters: {'n_neighbors': 137, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'manhattan'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:42,973] Trial 10 finished with value: 1.0 and parameters: {'n_neighbors': 160, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:43,941] Trial 11 finished with value: 1.0 and parameters: {'n_neighbors': 190, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:47,774] Trial 12 finished with value: 1.0 and parameters: {'n_neighbors': 167, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:48,772] Trial 13 finished with value: 1.0 and parameters: {'n_neighbors': 198, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:49,700] Trial 14 finished with value: 1.0 and parameters: {'n_neighbors': 168, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:50,615] Trial 15 finished with value: 1.0 and parameters: {'n_neighbors': 138, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:51,583] Trial 16 finished with value: 1.0 and parameters: {'n_neighbors': 172, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:53,814] Trial 17 finished with value: 1.0 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'algorithm': 'ball_tree', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:55,503] Trial 18 finished with value: 1.0 and parameters: {'n_neighbors': 115, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'manhattan'}. Best is trial 3 with value: 1.0.\n",
      "[I 2025-07-16 11:13:56,394] Trial 19 finished with value: 1.0 and parameters: {'n_neighbors': 152, 'weights': 'distance', 'algorithm': 'auto', 'metric': 'euclidean'}. Best is trial 3 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry: {'n_neighbors': 197, 'weights': 'distance', 'algorithm': 'brute', 'metric': 'euclidean'}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 200) # Liczba sąsiadów\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance']) #Sposób ważenia sąsiadów\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "    metric=trial.suggest_categorical('metric',['euclidean','manhattan'])\n",
    "    \n",
    "    model = KNeighborsClassifier(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=weights,\n",
    "        algorithm=algorithm,\n",
    "        metric=metric,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "    return test_model(model)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Najlepsze parametry:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:     0.7823\n",
      "F1:           0.8740\n",
      "Precision:    0.7801\n",
      "Sensitivity:  0.9935\n",
      "Specificity:  0.1137\n",
      "TP:           4920\n",
      "FP:           1387\n",
      "TN:           178\n",
      "FN:           32\n",
      "         Pred 0    Pred 1\n",
      "True 0     178     1387\n",
      "True 1      32     4920\n"
     ]
    }
   ],
   "source": [
    "best_model = KNeighborsClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print_error_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 11:13:57,261] A new study created in memory with name: no-name-6cb86c0f-8454-4969-bc5a-b9b0896fcf30\n",
      "[I 2025-07-16 11:13:57,281] Trial 0 finished with value: 0.852773826458037 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 0 with value: 0.852773826458037.\n",
      "[I 2025-07-16 11:13:59,022] Trial 1 finished with value: 0.9460771519548989 and parameters: {'criterion': 'log_loss', 'splitter': 'best', 'max_depth': 12, 'min_samples_split': 18, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 1 with value: 0.9460771519548989.\n",
      "[I 2025-07-16 11:14:00,667] Trial 2 finished with value: 0.9505683595786839 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 16, 'max_features': None}. Best is trial 2 with value: 0.9505683595786839.\n",
      "[I 2025-07-16 11:14:00,702] Trial 3 finished with value: 0.8696706601348402 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 16, 'max_features': None}. Best is trial 2 with value: 0.9505683595786839.\n",
      "[I 2025-07-16 11:14:00,728] Trial 4 finished with value: 0.9200938232994527 and parameters: {'criterion': 'gini', 'splitter': 'random', 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 14, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9505683595786839.\n",
      "[I 2025-07-16 11:14:00,781] Trial 5 finished with value: 0.9069977880554997 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 2 with value: 0.9505683595786839.\n",
      "[I 2025-07-16 11:14:01,035] Trial 6 finished with value: 0.9315548230931657 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 11, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 2 with value: 0.9505683595786839.\n",
      "[I 2025-07-16 11:14:02,245] Trial 7 finished with value: 0.9084108469905015 and parameters: {'criterion': 'entropy', 'splitter': 'best', 'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 11, 'max_features': None}. Best is trial 2 with value: 0.9505683595786839.\n",
      "[I 2025-07-16 11:14:02,319] Trial 8 finished with value: 0.9346229440364126 and parameters: {'criterion': 'entropy', 'splitter': 'random', 'max_depth': 14, 'min_samples_split': 12, 'min_samples_leaf': 17, 'max_features': None}. Best is trial 2 with value: 0.9505683595786839.\n",
      "[I 2025-07-16 11:14:02,349] Trial 9 finished with value: 0.9262223140069182 and parameters: {'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 19, 'max_features': 'sqrt'}. Best is trial 2 with value: 0.9505683595786839.\n",
      "[I 2025-07-16 11:14:02,598] Trial 10 finished with value: 0.9500393184796855 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 11, 'max_features': 'log2'}. Best is trial 2 with value: 0.9505683595786839.\n",
      "[I 2025-07-16 11:14:02,839] Trial 11 finished with value: 0.956245110821382 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 12, 'max_features': 'log2'}. Best is trial 11 with value: 0.956245110821382.\n",
      "[I 2025-07-16 11:14:03,118] Trial 12 finished with value: 0.952112676056338 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 14, 'max_features': 'log2'}. Best is trial 11 with value: 0.956245110821382.\n",
      "[I 2025-07-16 11:14:03,373] Trial 13 finished with value: 0.9530173313844227 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 13, 'max_features': 'log2'}. Best is trial 11 with value: 0.956245110821382.\n",
      "[I 2025-07-16 11:14:03,632] Trial 14 finished with value: 0.9622916666666667 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 14 with value: 0.9622916666666667.\n",
      "[I 2025-07-16 11:14:03,878] Trial 15 finished with value: 0.9637696335078534 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 15 with value: 0.9637696335078534.\n",
      "[I 2025-07-16 11:14:04,156] Trial 16 finished with value: 0.9637696335078534 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 15 with value: 0.9637696335078534.\n",
      "[I 2025-07-16 11:14:04,436] Trial 17 finished with value: 0.9858082020244182 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 17 with value: 0.9858082020244182.\n",
      "[I 2025-07-16 11:14:04,728] Trial 18 finished with value: 0.9680717863105175 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 17 with value: 0.9858082020244182.\n",
      "[I 2025-07-16 11:14:05,023] Trial 19 finished with value: 0.9638353309015112 and parameters: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 17 with value: 0.9858082020244182.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry: {'criterion': 'gini', 'splitter': 'best', 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy','log_loss']) \n",
    "    splitter = trial.suggest_categorical('splitter', ['best', 'random'])\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20) \n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    #DODAJ CCP_ALPHA\n",
    "\n",
    "    model = DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        splitter=splitter,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "    return test_model(model)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Najlepsze parametry:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:     0.5753\n",
      "F1:           0.6848\n",
      "Precision:    0.7851\n",
      "Sensitivity:  0.6072\n",
      "Specificity:  0.4741\n",
      "TP:           3007\n",
      "FP:           823\n",
      "TN:           742\n",
      "FN:           1945\n",
      "         Pred 0    Pred 1\n",
      "True 0     742      823\n",
      "True 1    1945     3007\n"
     ]
    }
   ],
   "source": [
    "best_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print_error_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 11:14:05,313] A new study created in memory with name: no-name-3bf70a60-b7d2-42cb-91ed-f4d89ef096e0\n",
      "[I 2025-07-16 11:14:17,561] Trial 0 finished with value: 0.9361818813275977 and parameters: {'n_estimators': 91, 'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 16, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9361818813275977.\n",
      "[I 2025-07-16 11:14:40,554] Trial 1 finished with value: 0.9355880201199531 and parameters: {'n_estimators': 144, 'criterion': 'log_loss', 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9361818813275977.\n",
      "[I 2025-07-16 11:14:54,776] Trial 2 finished with value: 0.9344205670421971 and parameters: {'n_estimators': 138, 'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 0 with value: 0.9361818813275977.\n",
      "[I 2025-07-16 11:15:12,281] Trial 3 finished with value: 0.9333836284725873 and parameters: {'n_estimators': 132, 'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 13, 'max_features': 'log2'}. Best is trial 0 with value: 0.9361818813275977.\n",
      "[I 2025-07-16 11:15:35,843] Trial 4 finished with value: 0.9284119662152561 and parameters: {'n_estimators': 195, 'criterion': 'log_loss', 'max_depth': 11, 'min_samples_split': 17, 'min_samples_leaf': 14, 'max_features': 'log2'}. Best is trial 0 with value: 0.9361818813275977.\n",
      "[I 2025-07-16 11:15:50,504] Trial 5 finished with value: 0.9403748415504752 and parameters: {'n_estimators': 105, 'criterion': 'entropy', 'max_depth': 36, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 5 with value: 0.9403748415504752.\n",
      "[I 2025-07-16 11:16:12,835] Trial 6 finished with value: 0.9326257865116976 and parameters: {'n_estimators': 178, 'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 14, 'min_samples_leaf': 13, 'max_features': 'sqrt'}. Best is trial 5 with value: 0.9403748415504752.\n",
      "[I 2025-07-16 11:16:25,943] Trial 7 finished with value: 0.9308954069536448 and parameters: {'n_estimators': 104, 'criterion': 'log_loss', 'max_depth': 33, 'min_samples_split': 2, 'min_samples_leaf': 16, 'max_features': 'log2'}. Best is trial 5 with value: 0.9403748415504752.\n",
      "[I 2025-07-16 11:16:33,094] Trial 8 finished with value: 0.9323789160904872 and parameters: {'n_estimators': 56, 'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 13, 'min_samples_leaf': 14, 'max_features': 'log2'}. Best is trial 5 with value: 0.9403748415504752.\n",
      "[I 2025-07-16 11:17:02,139] Trial 9 finished with value: 0.9384746474525121 and parameters: {'n_estimators': 174, 'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 5 with value: 0.9403748415504752.\n",
      "[I 2025-07-16 11:17:11,290] Trial 10 finished with value: 0.9417933983613329 and parameters: {'n_estimators': 60, 'criterion': 'entropy', 'max_depth': 41, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9417933983613329.\n",
      "[I 2025-07-16 11:17:19,686] Trial 11 finished with value: 0.9408652435517592 and parameters: {'n_estimators': 53, 'criterion': 'entropy', 'max_depth': 42, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9417933983613329.\n",
      "[I 2025-07-16 11:17:28,024] Trial 12 finished with value: 0.9406020318616243 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'max_depth': 45, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 10 with value: 0.9417933983613329.\n",
      "[I 2025-07-16 11:17:39,874] Trial 13 finished with value: 0.9422397923754016 and parameters: {'n_estimators': 73, 'criterion': 'entropy', 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 13 with value: 0.9422397923754016.\n",
      "[I 2025-07-16 11:17:50,500] Trial 14 finished with value: 0.9296519917861886 and parameters: {'n_estimators': 79, 'criterion': 'entropy', 'max_depth': 40, 'min_samples_split': 3, 'min_samples_leaf': 20, 'max_features': 'log2'}. Best is trial 13 with value: 0.9422397923754016.\n",
      "[I 2025-07-16 11:18:01,860] Trial 15 finished with value: 0.9400856526336359 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 13 with value: 0.9422397923754016.\n",
      "[I 2025-07-16 11:18:11,650] Trial 16 finished with value: 0.938487170625795 and parameters: {'n_estimators': 70, 'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 13 with value: 0.9422397923754016.\n",
      "[I 2025-07-16 11:18:28,253] Trial 17 finished with value: 0.9419006593198356 and parameters: {'n_estimators': 112, 'criterion': 'entropy', 'max_depth': 49, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 13 with value: 0.9422397923754016.\n",
      "[I 2025-07-16 11:18:44,384] Trial 18 finished with value: 0.9395680319164759 and parameters: {'n_estimators': 112, 'criterion': 'gini', 'max_depth': 47, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 13 with value: 0.9422397923754016.\n",
      "[I 2025-07-16 11:19:06,275] Trial 19 finished with value: 0.9391998326283227 and parameters: {'n_estimators': 156, 'criterion': 'log_loss', 'max_depth': 37, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 13 with value: 0.9422397923754016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry: {'n_estimators': 73, 'criterion': 'entropy', 'max_depth': 40, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 200) # liczba drzew w lesie\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 50) # Maksymalna głebokość drzewa\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20) # Minimalna liczba próbek w węźle wymagana do podzielenia\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20) # minimalna liczba próbek w liściu\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2']) # Liczba cech rozważanych podczas rodzielania węzła\n",
    "    \n",
    "    model = RandomForestClassifier(\n",
    "        criterion=criterion,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    \n",
    "    score = cross_val_score(model, X_val, y_val, cv=5, scoring='f1').mean()\n",
    "    return score \n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Najlepsze parametry:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.25      0.32      1565\n",
      "         1.0       0.79      0.91      0.85      4952\n",
      "\n",
      "    accuracy                           0.75      6517\n",
      "   macro avg       0.63      0.58      0.58      6517\n",
      "weighted avg       0.71      0.75      0.72      6517\n",
      "\n",
      "Accuracy:     0.7491\n",
      "F1:           0.8462\n",
      "Precision:    0.7921\n",
      "Sensitivity:  0.9081\n",
      "Specificity:  0.2460\n",
      "TP:           4497\n",
      "FP:           1180\n",
      "TN:           385\n",
      "FN:           455\n",
      "         Pred 0    Pred 1\n",
      "True 0     385     1180\n",
      "True 1     455     4497\n"
     ]
    }
   ],
   "source": [
    "best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print_error_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Wczytanie danych\n",
    "train = pd.read_csv(\"dataset_train.csv\")\n",
    "test = pd.read_csv(\"dataset_test.csv\")\n",
    "\n",
    "# Przekształcenie kolumny 'arrytmia'\n",
    "test['arrytmia'] = test['arrytmia'].apply(lambda x: 1 if x > 1 else x)\n",
    "train['arrytmia'] = train['arrytmia'].apply(lambda x: 1 if x > 1 else x)\n",
    "\n",
    "test['arrytmia'] = test['arrytmia'].apply(lambda x: -1 if x == 0 else x)\n",
    "train['arrytmia'] = train['arrytmia'].apply(lambda x: -1 if x == 0 else x)\n",
    "\n",
    "# Przygotowanie danych\n",
    "X_train = train.iloc[:, 1:]  # zakładam, że pierwsza kolumna to np. indeks/czas\n",
    "y_train = train['arrytmia'].values\n",
    "\n",
    "X_test = test.iloc[:, 1:]\n",
    "y_test = test['arrytmia'].values\n",
    "\n",
    "# Normalizacja\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-16 11:19:22,110] A new study created in memory with name: no-name-4cd17899-4dd4-4b0a-a9ad-61f9e9b499f3\n",
      "[I 2025-07-16 11:19:28,477] Trial 0 finished with value: 0.853188030537361 and parameters: {'C': 0.01547506364651005, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 0 with value: 0.853188030537361.\n",
      "[I 2025-07-16 11:19:39,076] Trial 1 finished with value: 0.8517649141557048 and parameters: {'C': 0.0015775671125333732, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.853188030537361.\n",
      "[I 2025-07-16 11:19:46,237] Trial 2 finished with value: 0.731486853427713 and parameters: {'C': 7174.277706667908, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.853188030537361.\n",
      "[I 2025-07-16 11:20:35,026] Trial 3 finished with value: 0.9059298976056105 and parameters: {'C': 2084.653923350255, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 3 with value: 0.9059298976056105.\n",
      "[I 2025-07-16 11:20:48,427] Trial 4 finished with value: 0.899829657269068 and parameters: {'C': 198.02101657379356, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 3 with value: 0.9059298976056105.\n",
      "[I 2025-07-16 11:20:59,266] Trial 5 finished with value: 0.8645661087833247 and parameters: {'C': 5.178220971206796, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 3 with value: 0.9059298976056105.\n",
      "[I 2025-07-16 11:21:05,449] Trial 6 finished with value: 0.8517649141557048 and parameters: {'C': 0.00013111525416307837, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 3 with value: 0.9059298976056105.\n",
      "[I 2025-07-16 11:21:12,019] Trial 7 finished with value: 0.8789747889436603 and parameters: {'C': 2.331779212179278, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 3 with value: 0.9059298976056105.\n",
      "[I 2025-07-16 11:21:18,525] Trial 8 finished with value: 0.8863650660711814 and parameters: {'C': 279.8397310885606, 'kernel': 'poly', 'gamma': 'auto', 'degree': 4, 'coef0': 0.13877893516966644}. Best is trial 3 with value: 0.9059298976056105.\n",
      "[I 2025-07-16 11:21:24,665] Trial 9 finished with value: 0.8664822164808854 and parameters: {'C': 0.6036146253529558, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 3 with value: 0.9059298976056105.\n",
      "[I 2025-07-16 11:21:30,121] Trial 10 finished with value: 0.8513925826551443 and parameters: {'C': 23820.189142180396, 'kernel': 'poly', 'gamma': 'scale', 'degree': 2, 'coef0': -0.9630970000417036}. Best is trial 3 with value: 0.9059298976056105.\n",
      "[I 2025-07-16 11:21:46,595] Trial 11 finished with value: 0.9032995714949941 and parameters: {'C': 308.439445937478, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 3 with value: 0.9059298976056105.\n",
      "[I 2025-07-16 11:22:06,644] Trial 12 finished with value: 0.9044721755759435 and parameters: {'C': 482.1102286649498, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 3 with value: 0.9059298976056105.\n",
      "[I 2025-07-16 11:29:26,830] Trial 13 finished with value: 0.9067752472063969 and parameters: {'C': 47360.85696672713, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 13 with value: 0.9067752472063969.\n",
      "[I 2025-07-16 11:35:43,193] Trial 14 finished with value: 0.9070630669465182 and parameters: {'C': 25637.448688241722, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 14 with value: 0.9070630669465182.\n",
      "[I 2025-07-16 11:45:49,450] Trial 15 finished with value: 0.9074564580368009 and parameters: {'C': 97067.56391510127, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 15 with value: 0.9074564580368009.\n",
      "[W 2025-07-16 11:55:30,270] Trial 16 failed with parameters: {'C': 99784.57369443528, 'kernel': 'rbf', 'gamma': 'scale'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Kuba\\AppData\\Local\\Temp\\ipykernel_22852\\646782139.py\", line 14, in objective\n",
      "    score = cross_val_score(model, X_val, y_val, cv=5, scoring='f1').mean()\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 684, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 216, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 411, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1863, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py\", line 1792, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 258, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"c:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 336, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "        ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-16 11:55:30,307] Trial 16 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score \n\u001b[0;32m     17\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNajlepsze parametry:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     model \u001b[38;5;241m=\u001b[39m SVC(C\u001b[38;5;241m=\u001b[39mC, kernel\u001b[38;5;241m=\u001b[39mkernel, gamma\u001b[38;5;241m=\u001b[39mgamma, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:411\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 411\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 866\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:258\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    257\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 258\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\Users\\Kuba\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:336\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    322\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    326\u001b[0m (\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 336\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_weight_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    C = trial.suggest_float('C', 1e-5, 1e5,log=True)\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    \n",
    "    if kernel == 'poly':\n",
    "        degree = trial.suggest_int('degree', 2, 5)\n",
    "        coef0 = trial.suggest_float ('coef0', -1, 1)\n",
    "        model = SVC(C=C, kernel=kernel, gamma=gamma, degree=degree, coef0=coef0, random_state=42)\n",
    "    else:\n",
    "        model = SVC(C=C, kernel=kernel, gamma=gamma, random_state=42)\n",
    "    \n",
    "    \n",
    "    score = cross_val_score(model, X_val, y_val, cv=5, scoring='f1').mean()\n",
    "    return score \n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Najlepsze parametry:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.57      0.69      1856\n",
      "         1.0       0.72      0.94      0.82      2257\n",
      "\n",
      "    accuracy                           0.77      4113\n",
      "   macro avg       0.81      0.75      0.75      4113\n",
      "weighted avg       0.80      0.77      0.76      4113\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = SVC(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print_error_matrix(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
